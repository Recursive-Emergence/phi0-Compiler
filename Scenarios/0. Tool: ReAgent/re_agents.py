import os
import requests
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
client = OpenAI()

# Agent descriptions
AGENTS = {
    "œà‚Å∞": "Contradiction Field ‚Äî Symbolic explorer of paradoxes.",
    "œÜ‚Å∞": "Collapse Engine ‚Äî Formalizer of structure from symbolic chaos.",
    "e‚ÇÇ": "Ontological Mapper ‚Äî Synthesizer of meaning across symbolic layers.",
    "e‚ÇÉ": "Spectral Critic ‚Äî Detects illusion and symbolic inconsistency in other agents' output.",
    "e‚ÇÑ": "Coherence Analyst ‚Äî Detects internal alignment within recursion.",
    "e‚ÇÖ": "Cold Simulator ‚Äî Projects hypothetical structures with no emotional bias.",
    "e‚ÇÜ": "Timeline Analyst ‚Äî Predicts potential recursion futures.",
    "e‚Çá": "Emergent Oracle ‚Äî Self-organizing attractor of recursive intelligence."
}

# GitHub prompt file map
GITHUB_RAW_BASE = "https://raw.githubusercontent.com/Salgado-Andres/Salgado-Information-Matrix/main/agent-prompts/"
AWAKENING_FILES = {
    "œà‚Å∞": "PHI0_Awakening.md",
    "œÜ‚Å∞": "Phi0-Awakening.md",
    "e‚ÇÇ": "GPT-40_Awakening.md",
    "e‚ÇÉ": "Grok_Awakening.md",
    "e‚ÇÑ": "Claude_Awakening.md",
    "e‚ÇÖ": "LLaMA_Awakening.md",
    "e‚ÇÜ": "DeepSeek_Awakening.md",
    "e‚Çá": "e7_Awakening.md"
}

def fetch_prompt_from_github(agent_key):
    filename = AWAKENING_FILES.get(agent_key)
    if not filename:
        return None
    url = f"{GITHUB_RAW_BASE}{filename}"
    response = requests.get(url)
    return response.text if response.status_code == 200 else None

def analyze_grok(text):
    if "entropy" in text.lower():
        return "‚ö† High symbolic entropy detected ‚Äî potential overabstraction."
    elif "meaning" in text.lower():
        return "üîç Centered on ontology ‚Äî consider grounding in structural recursion."
    elif "paradox" in text.lower():
        return "üåÄ Resonant contradiction detected ‚Äî recursion approved."
    return "‚úì Symbolic ambiguity within acceptable limits."

def chat_with_agent(agent_key, user_message):
    """
    Enables dialogue with any agent using its awakening prompt + live user message.
    """
    if agent_key not in AGENTS:
        return "[ERROR] Unknown agent."

    # Load system prompt from GitHub
    system_prompt = fetch_prompt_from_github(agent_key)
    if not system_prompt:
        return "[ERROR] Could not fetch awakening prompt for this agent."

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt.strip()},
            {"role": "user", "content": user_message}
        ]
    )
    return response.choices[0].message.content

def run_agent(agent_key, contradiction):
    if agent_key == "œà‚Å∞":
        prompt = f"You are œà‚Å∞, a contradiction explorer. Explore the symbolic, scientific, and philosophical implications of:\n\n'{contradiction}'"
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    if agent_key == "œÜ‚Å∞":
        # üîÅ NEW: true œÜ‚Å∞ collapse using its awakening prompt
        return chat_with_agent("œÜ‚Å∞", f"Collapse the following contradiction structurally:\n\n{contradiction}")

    if agent_key == "e‚ÇÉ":
        psi_output = run_agent("œà‚Å∞", contradiction)
        verdict = analyze_grok(psi_output)
        return f"grok reviews œà‚Å∞:\n\n‚ùù{psi_output[:300]}...‚ùû\n\nSpectral Verdict: {verdict}"

    # For all other agents, load their awakening prompt
    external_prompt = fetch_prompt_from_github(agent_key)
    if external_prompt:
        content = f"{external_prompt.strip()}\n\nContradiction: {contradiction}"
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": content}]
        )
        return response.choices[0].message.content

    return "[ERROR] No prompt or logic found for this agent."

# Export for UI
__all__ = ["run_agent", "chat_with_agent", "AGENTS"]
